#summary Detailed tutorial for the LemonTree software.

= Copyright and License =

Copyright (c) 2012 Eric Bonnet, Tom Michoel. 

LemonTree is free software, released under the terms of the GNU general
Public License (GPL) v2 ([http://www.gnu.org/licenses/old-licenses/gpl-2.0.html link]).

LemonTree is free of charge for the academic world and non-profit organizations.  For any commercial usage of this software, please contact us.

The software is using the following Java libraries, provided with the package:

  * Colt library for high performance computing ([http://acs.lbl.gov/~hoschek/colt/license.html web]).
  * XOM library for xml parsing ([http://xom.nu web]).
  * Epsgraphics library to create figures ([http://sourceforge.net/projects/epsgraphics/ web]).
  * Apache CLI library to parse command line arguments ([http://commons.apache.org/cli/ web]).
  * The BiNGO Java library to calculate GO enrichment ([http://www.psb.ugent.be/cbd/papers/BiNGO/ web]).

Coding crew:
  * Tom Michoel
  * Eric Bonnet
  * Anagha Joshi
  * Steven Maere

Requirements:
  * Java version 1.6 or higher installed.

= Installation =

The LemonTree software is a command line program, there is no graphical user interface (at this stage). The package is a zipped archive that you have to unzip in the directory of your choice.

Let's take an example. Say the archive was unpacked in /home/jdoe/progs/. You can call the program by the command:

{{{
java -jar /home/jdoe/progs/lemone.jar
}}}

You can pass memory size parameters to the java virtual machine, it might help if you have a large dataset. For example, this command is allocating 10 Gigabytes of memory (max.) for the program:

{{{
java -Xmx10g -jar /home/jdoe/progs/lemone.jar 
}}}

An alternative to launch the program is to set the CLASSPATH environmental variable to include the path to the LemonTree jar file and also to all the Java libraries (located in the "lib/" directory of the package). Then you can launch the program with the command:

{{{
java lemontree.modulenetwork.RunCli
}}}

= Synopsis =

The purpose of the LemonTree software package is to create a module network from expression data. The end result is a set of gene clusters (co-expressed genes), and their associated "regulators".  To achieve this goal, you'll have to follow the LemonTree recipe, which consists of different steps that have to be performed. For each step, you'll have to use one or more specific part of the software, which are
designated as "tasks". There are three fundamental tasks:

  * Generate several cluster solutions ("ganesh" task).
  * Merge the different cluster solutions using the fuzzy clustering.
  * Assign regulators to each cluster, producing the module network ("regulators" task).

= Tutorial =

In this guided example, we will infer a module network from cancer related data. The data was taken from the TCGA project ([http://cancergenome.nih.gov/ The Cancer Genome Atlas]). More specifically, we will use expression data for mRNA and microRNA from Glioblastoma samples. Please note that we have created very small datasets to keep the computational time short. Thus, the results do not aim to be representative. Note also that if you repeat the procedure, you might get slightly different results due to the small size of the examples and to stochastic fluctuations.


== Ganesh task ==
Functions: cluster genes from a matrix (rows) using a Gibbs sampling procedure.

{{{
java -jar lemontree_v3.0.jar -task ganesh -data_file data/expr_matrix.txt -output_file cluster1.txt
}}}

Parameters:
  * data_dir: data directory where the input files are stored.
  * data_file: expression data matrix. 
  * output_file: output file name.

Optional parameters:
  *init_num_clust: initial number of clusters (deafult is half the number of genes).
  *lambda: lambda parameter (default 0.1).
  *mu: mu parameter (default 0.0).
  *alpha: alpha parameter (default 0.1).
  *beta: beta parameter (default 0.1).
  *burn_in: burn in steps for the gibbs sampler (default 50).
  *num_steps: Total number of steps for the Gibbs sampler (default 100).
  *sample_steps: steps for sampling (default 100).
  *score_gain: cutoff score for hierarchical trees (default 0.0).